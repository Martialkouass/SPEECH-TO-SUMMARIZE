# -*- coding: utf-8 -*-
"""speech to text and sum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dNW4sqBCezVdYrUcX96cGyZbSNnZpy1m

**I-Install the Python packages needed to use Whisper models**
"""

! pip install git+https://github.com/openai/whisper.git
!pip install --upgrade pip
!pip install gradio
!pip install textsum

from IPython.display import Audio
import torch
import gradio as gr
from textsum.summarize import Summarizer
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

"""**II- SPEECH TO TEXT**"""

def transcribe (audio_file_path: str) :
  device = "cuda:0" if torch.cuda.is_available() else "cpu"
  torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
  model_id = "openai/whisper-large-v3-turbo"
  model = AutoModelForSpeechSeq2Seq.from_pretrained(
      model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
      )
  model.to(device)
  processor = AutoProcessor.from_pretrained(model_id)
  pipe = pipeline(
      "automatic-speech-recognition",
      model=model,
      tokenizer=processor.tokenizer,
      feature_extractor=processor.feature_extractor,
      torch_dtype=torch_dtype,
      device=device,
      )
  generate_kwargs = {
    "max_new_tokens": 400,
    "num_beams": 1,
    "condition_on_prev_tokens": False,
    "compression_ratio_threshold": 1.35,  # zlib compression ratio threshold (in token space)
    "temperature": (0.0, 0.2, 0.4, 0.6, 0.8, 1.0),
    "logprob_threshold": -1.0,
    "no_speech_threshold": 0.6,
    "return_timestamps": True,
    }
  result = pipe(audio_file_path, generate_kwargs=generate_kwargs)["text"]
  return result

"""**III-SUMMURIZE TEXT**"""

def summarize (result):
  model_name = "pszemraj/led-large-book-summary"
  summarizer = Summarizer(
      model_name_or_path=model_name,
      token_batch_length=4096,
      )
  summary= summarizer.summarize_string(result)
  return summary

"""**IV-DEPLOYMENT ON GRADIO**"""

# Define the processing pipeline
def process_audio(audio):
  transcription = transcribe(audio)
  summary = summarize(transcription)
  # Save the transcript to a downloadable file
  transcript_file = "summary.txt"
  with open(transcript_file, "w") as transcript_f:
    transcript_f.write(summary)
  return summary,transcript_file

iface = gr.Interface(
    fn= process_audio,
    inputs= gr.Audio(type="filepath", label="Upload an audio file"),
    outputs=[
        gr.Textbox(
            label="Summary",
            show_copy_button=True,
            ),  # Display the summary generated
        gr.File(
            label="Download Transcript"
            ),  # Provide the transcript as a downloadable file
        ],
    analytics_enabled=False,
    title="Summarizer",
    description="Upload an audio file and get a summary of the key concepts discussed.",
    )

iface.launch(debug=True)